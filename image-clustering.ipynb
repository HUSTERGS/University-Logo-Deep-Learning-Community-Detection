{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"image-clustering.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["5B60vhwuBMKl"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"kVB0FfTv-rOA","colab_type":"text"},"source":["# TOOLS"]},{"cell_type":"code","metadata":{"id":"U2VfRbUB_BGQ","colab_type":"code","colab":{},"cellView":"form"},"source":["#@title utils.py\n","\"\"\"\n","\n"," utils.py (author: Anson Wong / git: ankonzoid)\n","\n","\"\"\"\n","import os, random\n","import numpy as np\n","\n","# Create directory (only if doesn't exist)\n","def makeDir(dir):\n","    if not os.path.exists(dir):\n","        os.makedirs(dir)\n","    return dir\n","\n","# Get split indices\n","def split(fracs, N, seed):\n","    fracs = [round(frac, 2) for frac in fracs]\n","    if sum(fracs) != 1.00:\n","        raise Exception(\"fracs do not sum to one!\")\n","\n","    # Shuffle ordered indices\n","    indices = list(range(N))\n","    random.Random(seed).shuffle(indices)\n","    indices = np.array(indices, dtype=int)\n","\n","    # Get numbers per group\n","    n_fracs = []\n","    for i in range(len(fracs) - 1):\n","        n_fracs.append(int(max(fracs[i] * N, 0)))\n","    n_fracs.append(int(max(N - sum(n_fracs), 0)))\n","\n","    if sum(n_fracs) != N:\n","        raise Exception(\"n_fracs do not sum to N!\")\n","\n","    # Sample indices\n","    n_selected = 0\n","    indices_fracs = []\n","    for n_frac in n_fracs:\n","        indices_frac = indices[n_selected:n_selected + n_frac]\n","        indices_fracs.append(indices_frac)\n","        n_selected += n_frac\n","\n","    # Check no intersections\n","    for a, indices_frac_A in enumerate(indices_fracs):\n","        for b, indices_frac_B in enumerate(indices_fracs):\n","            if a == b:\n","                continue\n","            if is_intersect(indices_frac_A, indices_frac_B):\n","                raise Exception(\"there are intersections!\")\n","\n","    return indices_fracs\n","\n","# Is there intersection?\n","def is_intersect(arr1, arr2):\n","    n_intersect = len(np.intersect1d(arr1, arr2))\n","    if n_intersect == 0: return False\n","    else: return True\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bCN3KY2x_KMf","colab_type":"code","colab":{},"cellView":"form"},"source":["#@title CV_IO_utils\n","\"\"\"\n","\n"," CV_IO_utils.py  (author: Anson Wong / git: ankonzoid)\n","\n","\"\"\"\n","import os\n","import skimage.io\n","from multiprocessing import Pool\n","\n","# Read image\n","def read_img(filePath):\n","    return skimage.io.imread(filePath, as_gray=False)\n","\n","# Read images with common extensions from a directory\n","def read_imgs_dir(dirPath, extensions, parallel=True):\n","    args = [os.path.join(dirPath, filename)\n","            for filename in os.listdir(dirPath)\n","            if any(filename.lower().endswith(ext) for ext in extensions)]\n","    if parallel:\n","        pool = Pool()\n","        imgs = pool.map(read_img, args)\n","        pool.close()\n","        pool.join()\n","    else:\n","        imgs = [read_img(arg) for arg in args]\n","        names = [os.path.splitext(os.path.basename(arg))[0] for arg in args]\n","    return imgs, names\n","\n","# Save image to file\n","def save_img(filePath, img):\n","    skimage.io.imsave(filePath, img)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r4i_Zkww_WS1","colab_type":"code","colab":{},"cellView":"form"},"source":["#@title CV_Plot_utils\n","\"\"\"\n","\n"," CV_plot_utils.py  (author: Anson Wong / git: ankonzoid)\n","\n","\"\"\"\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib import offsetbox\n","from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n","from sklearn import manifold\n","\n","# Plot image\n","def plot_img(img, range=[0, 255]):\n","    plt.imshow(img, vmin=range[0], vmax=range[1])\n","    plt.xlabel(\"xpixels\")\n","    plt.ylabel(\"ypixels\")\n","    plt.tight_layout()\n","    plt.show()\n","    plt.close()\n","\n","# Plots images in 2 rows: top row is query, bottom row is answer\n","def plot_query_retrieval(img_query, imgs_retrieval, outFile):\n","    n_retrieval = len(imgs_retrieval)\n","    fig = plt.figure(figsize=(2*n_retrieval, 4))\n","    fig.suptitle(\"Image Retrieval (k={})\".format(n_retrieval), fontsize=25)\n","\n","    # Plot query image\n","    ax = plt.subplot(2, n_retrieval, 0 + 1)\n","    plt.imshow(img_query)\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    for axis in ['top', 'bottom', 'left', 'right']:\n","        ax.spines[axis].set_linewidth(4)  # increase border thickness\n","        ax.spines[axis].set_color('black')  # set to black\n","    ax.set_title(\"query\",  fontsize=14)  # set subplot title\n","\n","    # Plot retrieval images\n","    for i, img in enumerate(imgs_retrieval):\n","        ax = plt.subplot(2, n_retrieval, n_retrieval + i + 1)\n","        plt.imshow(img)\n","        ax.get_xaxis().set_visible(False)\n","        ax.get_yaxis().set_visible(False)\n","        for axis in ['top', 'bottom', 'left', 'right']:\n","            ax.spines[axis].set_linewidth(1)  # set border thickness\n","            ax.spines[axis].set_color('black')  # set to black\n","        ax.set_title(\"Rank #%d\" % (i+1), fontsize=14)  # set subplot title\n","\n","    if outFile is None:\n","        plt.show()\n","    else:\n","        plt.savefig(outFile, bbox_inches='tight')\n","    plt.close()\n","\n","# Plot t-SNE of images\n","def plot_tsne(X, imgs, outFile):\n","\n","    def imscatter(x, y, images, ax=None, zoom=1.0):\n","        if ax is None:\n","            ax = plt.gca()\n","        x, y = np.atleast_1d(x, y)\n","        artists = []\n","        for x0, y0, img0 in zip(x, y, images):\n","            im = OffsetImage(img0, zoom=zoom)\n","            ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=True)\n","            artists.append(ax.add_artist(ab))\n","        ax.update_datalim(np.column_stack([x, y]))\n","        ax.autoscale()\n","        return artists\n","\n","    def plot_embedding(X, imgs, title=None):\n","        x_min, x_max = np.min(X, 0), np.max(X, 0)\n","        X = (X - x_min) / (x_max - x_min)\n","\n","        plt.figure(num=None, figsize=(80, 45), dpi=200, facecolor='w', edgecolor='k')\n","        ax = plt.subplot(111)\n","        for i in range(X.shape[0]):\n","            plt.text(X[i, 0], X[i, 1], \".\", fontdict={'weight': 'bold', 'size': 9})\n","        if hasattr(offsetbox, 'AnnotationBbox'):\n","            imscatter(X[:,0], X[:,1], imgs, zoom=0.3, ax=ax)\n","\n","        plt.xticks([]), plt.yticks([])\n","        if title is not None:\n","            plt.title(title, fontsize=18)\n","\n","    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n","    X_tsne = tsne.fit_transform(X)\n","    plot_embedding(X_tsne, imgs, \"t-SNE embeddings\")\n","    if outFile is None:\n","        plt.show()\n","    else:\n","        plt.savefig(outFile, bbox_inches='tight')\n","    plt.close()\n","\n","# Plot Isomap of images\n","def plot_isomap(X, imgs, outFile):\n","\n","    def imscatter(x, y, images, ax=None, zoom=1.0):\n","        if ax is None:\n","            ax = plt.gca()\n","        x, y = np.atleast_1d(x, y)\n","        artists = []\n","        for x0, y0, img0 in zip(x, y, images):\n","            im = OffsetImage(img0, zoom=zoom)\n","            ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=True)\n","            artists.append(ax.add_artist(ab))\n","        ax.update_datalim(np.column_stack([x, y]))\n","        ax.autoscale()\n","        return artists\n","\n","    def plot_embedding(X, imgs, title=None):\n","        x_min, x_max = np.min(X, 0), np.max(X, 0)\n","        X = (X - x_min) / (x_max - x_min)\n","\n","        plt.figure(num=None, figsize=(80, 45), dpi=200, facecolor='w', edgecolor='k')\n","        ax = plt.subplot(111)\n","        for i in range(X.shape[0]):\n","            plt.text(X[i, 0], X[i, 1], \".\", fontdict={'weight': 'bold', 'size': 9})\n","        if hasattr(offsetbox, 'AnnotationBbox'):\n","            imscatter(X[:,0], X[:,1], imgs, zoom=0.3, ax=ax)\n","\n","        plt.xticks([]), plt.yticks([])\n","        if title is not None:\n","            plt.title(title, fontsize=18)\n","\n","    isomap = manifold.Isomap(n_components=2)\n","    X_isomap = isomap.fit_transform(X)\n","    plot_embedding(X_isomap, imgs, \"Isomap embeddings\")\n","    if outFile is None:\n","        plt.show()\n","    else:\n","        plt.savefig(outFile, bbox_inches='tight')\n","    plt.close()\n","\n","# Plot image reconstructions\n","def plot_reconstructions(imgs, imgs_reconstruct, outFile,\n","                         range_imgs=[0, 255],\n","                         range_imgs_reconstruct=[0, 1]):\n","    # Create plot to save\n","    assert len(imgs) == len(imgs_reconstruct)\n","    fig = plt.figure(figsize=(20, 4))\n","    fig.suptitle(\"Image Reconstructions\", fontsize=35)\n","    n = min(len(imgs), 10)\n","    for i in range(n):\n","\n","        # Plot original image\n","        ax = plt.subplot(2, n, i + 1)\n","        plt.imshow(imgs[i],\n","                   vmin=range_imgs[0],\n","                   vmax=range_imgs[1])\n","        ax.get_xaxis().set_visible(False)\n","        ax.get_yaxis().set_visible(False)\n","\n","        # Plot reconstructed image\n","        ax = plt.subplot(2, n, n + i + 1)\n","        plt.imshow(imgs_reconstruct[i],\n","                   vmin=range_imgs_reconstruct[0],\n","                   vmax=range_imgs_reconstruct[1])\n","        ax.get_xaxis().set_visible(False)\n","        ax.get_yaxis().set_visible(False)\n","\n","    if outFile is None:\n","        plt.show()\n","    else:\n","        plt.savefig(outFile, bbox_inches='tight')\n","    plt.close()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VpJ0FH5S_dxy","colab_type":"code","colab":{},"cellView":"form"},"source":["#@title CV_transform_utils\n","\"\"\"\n","\n"," CV_transform_utils.py  (author: Anson Wong / git: ankonzoid)\n","\n","\"\"\"\n","from multiprocessing import Pool\n","from skimage.transform import resize\n","\n","# Apply transformations to multiple images\n","def apply_transformer(imgs, transformer, parallel=True):\n","    if parallel:\n","        pool = Pool()\n","        imgs_transform = pool.map(transformer, [img for img in imgs])\n","        pool.close()\n","        pool.join()\n","    else:\n","        imgs_transform = [transformer(img) for img in imgs]\n","    return imgs_transform\n","\n","# Normalize image data [0, 255] -> [0.0, 1.0]\n","def normalize_img(img):\n","    return img / 255.\n","\n","# Resize image\n","def resize_img(img, shape_resized):\n","    img_resized = resize(img, shape_resized,\n","                         anti_aliasing=True,\n","                         preserve_range=True)\n","    assert img_resized.shape == shape_resized\n","    return img_resized\n","\n","# Flatten image\n","def flatten_img(img):\n","    return img.flatten(\"C\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T7CNplhR_lJQ","colab_type":"code","colab":{},"cellView":"form"},"source":["#@title autoencoder\n","\"\"\"\n","\n"," autoencoder.py  (author: Anson Wong / git: ankonzoid)\n","\n","\"\"\"\n","import numpy as np\n","import tensorflow as tf\n","\n","class AutoEncoder():\n","\n","    def __init__(self, modelName, info):\n","        self.modelName = modelName\n","        self.info = info\n","        self.autoencoder = None\n","        self.encoder = None\n","        self.decoder = None\n","\n","    # Train\n","    def fit(self, X, n_epochs=50, batch_size=256):\n","        indices_fracs = split(fracs=[0.9, 0.1], N=len(X), seed=0)\n","        X_train, X_valid = X[indices_fracs[0]], X[indices_fracs[1]]\n","        self.autoencoder.fit(X_train, X_train,\n","                             epochs = n_epochs,\n","                             batch_size = batch_size,\n","                             shuffle = True,\n","                             validation_data = (X_valid, X_valid))\n","\n","    # Inference\n","    def predict(self, X):\n","        return self.encoder.predict(X)\n","\n","    # Set neural network architecture\n","    def set_arch(self):\n","\n","        shape_img = self.info[\"shape_img\"]\n","        shape_img_flattened = (np.prod(list(shape_img)),)\n","\n","        # Set encoder and decoder graphs\n","        if self.modelName == \"simpleAE\":\n","            encode_dim = 128\n","\n","            input = tf.keras.Input(shape=shape_img_flattened)\n","            encoded = tf.keras.layers.Dense(encode_dim, activation='relu')(input)\n","\n","            decoded = tf.keras.layers.Dense(shape_img_flattened[0], activation='sigmoid')(encoded)\n","\n","        elif self.modelName == \"convAE\":\n","            n_hidden_1, n_hidden_2, n_hidden_3 = 16, 8, 8\n","            convkernel = (3, 3)  # convolution kernel\n","            poolkernel = (2, 2)  # pooling kernel\n","\n","            input = tf.keras.layers.Input(shape=shape_img)\n","            x = tf.keras.layers.Conv2D(n_hidden_1, convkernel, activation='relu', padding='same')(input)\n","            x = tf.keras.layers.MaxPooling2D(poolkernel, padding='same')(x)\n","            x = tf.keras.layers.Conv2D(n_hidden_2, convkernel, activation='relu', padding='same')(x)\n","            x = tf.keras.layers.MaxPooling2D(poolkernel, padding='same')(x)\n","            x = tf.keras.layers.Conv2D(n_hidden_3, convkernel, activation='relu', padding='same')(x)\n","            encoded = tf.keras.layers.MaxPooling2D(poolkernel, padding='same')(x)\n","\n","            x = tf.keras.layers.Conv2D(n_hidden_3, convkernel, activation='relu', padding='same')(encoded)\n","            x = tf.keras.layers.UpSampling2D(poolkernel)(x)\n","            x = tf.keras.layers.Conv2D(n_hidden_2, convkernel, activation='relu', padding='same')(x)\n","            x = tf.keras.layers.UpSampling2D(poolkernel)(x)\n","            x = tf.keras.layers.Conv2D(n_hidden_1, convkernel, activation='relu')(x)\n","            x = tf.keras.layers.UpSampling2D(poolkernel)(x)\n","            decoded = tf.keras.layers.Conv2D(shape_img[2], convkernel, activation='sigmoid', padding='same')(x)\n","\n","        else:\n","            raise Exception(\"Invalid model name given!\")\n","\n","        # Create autoencoder model\n","        autoencoder = tf.keras.Model(input, decoded)\n","        input_autoencoder_shape = autoencoder.layers[0].input_shape[1:]\n","        output_autoencoder_shape = autoencoder.layers[-1].output_shape[1:]\n","\n","        # Create encoder model\n","        encoder = tf.keras.Model(input, encoded)  # set encoder\n","        input_encoder_shape = encoder.layers[0].input_shape[1:]\n","        output_encoder_shape = encoder.layers[-1].output_shape[1:]\n","\n","        # Create decoder model\n","        decoded_input = tf.keras.Input(shape=output_encoder_shape)\n","        if self.modelName == 'simpleAE':\n","            decoded_output = autoencoder.layers[-1](decoded_input)  # single layer\n","        elif self.modelName == 'convAE':\n","            decoded_output = autoencoder.layers[-7](decoded_input)  # Conv2D\n","            decoded_output = autoencoder.layers[-6](decoded_output)  # UpSampling2D\n","            decoded_output = autoencoder.layers[-5](decoded_output)  # Conv2D\n","            decoded_output = autoencoder.layers[-4](decoded_output)  # UpSampling2D\n","            decoded_output = autoencoder.layers[-3](decoded_output)  # Conv2D\n","            decoded_output = autoencoder.layers[-2](decoded_output)  # UpSampling2D\n","            decoded_output = autoencoder.layers[-1](decoded_output)  # Conv2D\n","        else:\n","            raise Exception(\"Invalid model name given!\")\n","        decoder = tf.keras.Model(decoded_input, decoded_output)\n","        decoder_input_shape = decoder.layers[0].input_shape[1:]\n","        decoder_output_shape = decoder.layers[-1].output_shape[1:]\n","\n","        # Generate summaries\n","        print(\"\\nautoencoder.summary():\")\n","        print(autoencoder.summary())\n","        print(\"\\nencoder.summary():\")\n","        print(encoder.summary())\n","        print(\"\\ndecoder.summary():\")\n","        print(decoder.summary())\n","\n","        # Assign models\n","        self.autoencoder = autoencoder\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    # Compile\n","    def compile(self, loss=\"binary_crossentropy\", optimizer=\"adam\"):\n","        self.autoencoder.compile(optimizer=optimizer, loss=loss)\n","\n","    # Load model architecture and weights\n","    def load_models(self, loss=\"binary_crossentropy\", optimizer=\"adam\"):\n","        print(\"Loading models...\")\n","        self.autoencoder = tf.keras.models.load_model(self.info[\"autoencoderFile\"])\n","        self.encoder = tf.keras.models.load_model(self.info[\"encoderFile\"])\n","        self.decoder = tf.keras.models.load_model(self.info[\"decoderFile\"])\n","        self.autoencoder.compile(optimizer=optimizer, loss=loss)\n","        self.encoder.compile(optimizer=optimizer, loss=loss)\n","        self.decoder.compile(optimizer=optimizer, loss=loss)\n","\n","    # Save model architecture and weights to file\n","    def save_models(self):\n","        print(\"Saving models...\")\n","        self.autoencoder.save(self.info[\"autoencoderFile\"])\n","        self.encoder.save(self.info[\"encoderFile\"])\n","        self.decoder.save(self.info[\"decoderFile\"])\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EHgv6Pix_6bp","colab_type":"text"},"source":["# Image embedding"]},{"cell_type":"code","metadata":{"id":"WY1j_F1y_98B","colab_type":"code","colab":{}},"source":["\"\"\"\n","\n"," image_retrieval.py  (author: Anson Wong / git: ankonzoid)\n","\n"," We perform image retrieval using transfer learning on a pre-trained\n"," VGG image classifier. We plot the k=5 most similar images to our\n"," query images, as well as the t-SNE visualizations.\n","\n","\"\"\"\n","import os\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.neighbors import NearestNeighbors\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import sklearn\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aOtDqgx7_-qE","colab_type":"code","colab":{}},"source":["# Run mode\n","modelName = \"vgg19\"  # try: \"simpleAE\", \"convAE\", \"vgg19\"\n","trainModel = True\n","\n","# Make paths\n","dataTrainPath = os.path.join(os.getcwd(), \"data\", \"train\")\n","dataTestPath = os.path.join(os.getcwd(), \"data\", \"test\")\n","outPath = makeDir(os.path.join(os.getcwd(), \"output\", modelName))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MAHmTeAhAC6K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":468},"outputId":"8716a9e5-84ba-4110-8e6f-d9757c2ae70f","executionInfo":{"status":"error","timestamp":1563267449639,"user_tz":-480,"elapsed":804,"user":{"displayName":"唐龙飞","photoUrl":"","userId":"07557128654487741389"}}},"source":["# Read images\n","extensions = [\".jpg\", \".jpeg\"]\n","print(\"Reading train images from '{}'...\".format(dataTrainPath))\n","imgs_train, names_train = read_imgs_dir(dataTrainPath, extensions, parallel=False)\n","print(\"Reading test images from '{}'...\".format(dataTestPath))\n","imgs_test, names_test = read_imgs_dir(dataTestPath, extensions, parallel=False)\n","shape_img = imgs_train[0].shape\n","print(\"Image shape = {}\".format(shape_img))\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Reading train images from '/content/data/train'...\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-45a23569742b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".jpeg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading train images from '{}'...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataTrainPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimgs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_imgs_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataTrainPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading test images from '{}'...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataTestPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimgs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_imgs_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataTestPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-004aaa5c2170>\u001b[0m in \u001b[0;36mread_imgs_dir\u001b[0;34m(dirPath, extensions, parallel)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_imgs_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     args = [os.path.join(dirPath, filename)\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             if any(filename.lower().endswith(ext) for ext in extensions)]\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/train'"]}]},{"cell_type":"code","metadata":{"id":"Gu3_DjBZAD_E","colab_type":"code","colab":{}},"source":["# Build models\n","if modelName in [\"simpleAE\", \"convAE\"]:\n","\n","    # Set up autoencoder\n","    info = {\n","        \"shape_img\": shape_img,\n","        \"autoencoderFile\": os.path.join(outPath, \"{}_autoecoder.h5\".format(modelName)),\n","        \"encoderFile\": os.path.join(outPath, \"{}_encoder.h5\".format(modelName)),\n","        \"decoderFile\": os.path.join(outPath, \"{}_decoder.h5\".format(modelName)),\n","    }\n","    model = AutoEncoder(modelName, info)\n","    model.set_arch()\n","\n","    if modelName == \"simpleAE\":\n","        shape_img_resize = shape_img\n","        input_shape_model = (model.encoder.input.shape[1],)\n","        output_shape_model = (model.encoder.output.shape[1],)\n","        n_epochs = 500\n","    elif modelName == \"convAE\":\n","        shape_img_resize = shape_img\n","        input_shape_model = tuple([int(x) for x in model.encoder.input.shape[1:]])\n","        output_shape_model = tuple([int(x) for x in model.encoder.output.shape[1:]])\n","        n_epochs = 500\n","    else:\n","        raise Exception(\"Invalid modelName!\")\n","\n","elif modelName in [\"vgg19\"]:\n","\n","    # Load pre-trained VGG19 model + higher level layers\n","    print(\"Loading VGG19 pre-trained model...\")\n","    model = tf.keras.applications.VGG19(weights='imagenet', include_top=False,\n","                                        input_shape=shape_img)\n","    model.summary()\n","\n","    shape_img_resize = tuple([int(x) for x in model.input.shape[1:]])\n","    input_shape_model = tuple([int(x) for x in model.input.shape[1:]])\n","    output_shape_model = tuple([int(x) for x in model.output.shape[1:]])\n","    n_epochs = None\n","\n","else:\n","    raise Exception(\"Invalid modelName!\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lt_YVPqTATJt","colab_type":"code","colab":{}},"source":["# Print some model info\n","print(\"input_shape_model = {}\".format(input_shape_model))\n","print(\"output_shape_model = {}\".format(output_shape_model))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQdaZ8RZAVLq","colab_type":"code","colab":{}},"source":["# Apply transformations to all images\n","class ImageTransformer(object):\n","\n","    def __init__(self, shape_resize):\n","        self.shape_resize = shape_resize\n","\n","    def __call__(self, img):\n","        img_transformed = resize_img(img, self.shape_resize)\n","        img_transformed = normalize_img(img_transformed)\n","        return img_transformed\n","\n","transformer = ImageTransformer(shape_img_resize)\n","print(\"Applying image transformer to training images...\")\n","imgs_train_transformed = apply_transformer(imgs_train, transformer, parallel=True)\n","print(\"Applying image transformer to test images...\")\n","imgs_test_transformed = apply_transformer(imgs_test, transformer, parallel=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ENBaxx34AveR","colab_type":"code","colab":{}},"source":["# Convert images to numpy array\n","X_train = np.array(imgs_train_transformed).reshape((-1,) + input_shape_model)\n","X_test = np.array(imgs_test_transformed).reshape((-1,) + input_shape_model)\n","print(\" -> X_train.shape = {}\".format(X_train.shape))\n","print(\" -> X_test.shape = {}\".format(X_test.shape))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ss2L0DrNAvqi","colab_type":"code","colab":{}},"source":["# Train (if necessary)\n","if modelName in [\"simpleAE\", \"convAE\"]:\n","    if trainModel:\n","        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n","        model.fit(X_train, n_epochs=n_epochs, batch_size=256)\n","        model.save_models()\n","    else:\n","        model.load_models(loss=\"binary_crossentropy\", optimizer=\"adam\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cb9aqcLDAvtL","colab_type":"code","colab":{}},"source":["# Create embeddings using model\n","print(\"Inferencing embeddings using pre-trained model...\")\n","E_train = model.predict(X_train)\n","E_train_flatten = E_train.reshape((-1, np.prod(output_shape_model)))\n","E_test = model.predict(X_test)\n","E_test_flatten = E_test.reshape((-1, np.prod(output_shape_model)))\n","print(\" -> E_train.shape = {}\".format(E_train.shape))\n","print(\" -> E_test.shape = {}\".format(E_test.shape))\n","print(\" -> E_train_flatten.shape = {}\".format(E_train_flatten.shape))\n","print(\" -> E_test_flatten.shape = {}\".format(E_test_flatten.shape))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YIjWU1kXAvvi","colab_type":"code","colab":{}},"source":["# Save embeddings\n","print(\"Saving embedding datas...\")\n","outFile = os.path.join(outPath, \"names_train\")\n","np.save(outFile, names_train)\n","outFile = os.path.join(outPath, \"imgs_train\")\n","np.save(outFile, imgs_train)\n","outFile = os.path.join(outPath, \"X_train\")\n","np.save(outFile, X_train)\n","outFile = os.path.join(outPath, \"E_train\")\n","np.save(outFile, E_train)\n","outFile = os.path.join(outPath, \"E_train_flatten\")\n","np.save(outFile, E_train_flatten)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6eyGtnQuAv0n","colab_type":"code","colab":{}},"source":["# Make reconstruction visualizations\n","if modelName in [\"simpleAE\", \"convAE\"]:\n","    print(\"Visualizing database image reconstructions...\")\n","    imgs_train_reconstruct = model.decoder.predict(E_train)\n","    if modelName == \"simpleAE\":\n","        imgs_train_reconstruct = imgs_train_reconstruct.reshape((-1,) + shape_img_resize)\n","    plot_reconstructions(imgs_train, imgs_train_reconstruct,\n","                         os.path.join(outPath, \"{}_reconstruct.png\".format(modelName)),\n","                         range_imgs=[0, 255],\n","                         range_imgs_reconstruct=[0, 1])\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5B60vhwuBMKl","colab_type":"text"},"source":["# Read embedding"]},{"cell_type":"code","metadata":{"id":"lFxENE3NBN9Q","colab_type":"code","colab":{}},"source":["# Read embeddings\n","inFile = os.path.join(outPath, \"imgs_train.npy\")\n","imgs_train = np.load(inFile)\n","# inFile = os.path.join(outPath, \"X_train.npy\")\n","# X_train = np.load(inFile)\n","# inFile = os.path.join(outPath, \"E_train.npy\")\n","# E_train = np.load(inFile)\n","inFile = os.path.join(outPath, \"E_train_flatten.npy\")\n","E_train_flatten = np.load(inFile)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ru_pp4orA-3r","colab_type":"text"},"source":["# Dimemtion Reduction"]},{"cell_type":"code","metadata":{"id":"-iwDiwCJBBy5","colab_type":"code","colab":{}},"source":["# Plot t-SNE visualization\n","print(\"Visualizing t-SNE on training images...\")\n","outFile = os.path.join(outPath, \"{}_tsne.png\".format(modelName))\n","plot_tsne(E_train_flatten, imgs_train, outFile)\n","\n","# Plot Isomap visualization\n","print(\"Visualizing isomap on training images...\")\n","outFile = os.path.join(outPath, \"{}_isomap.png\".format(modelName))\n","plot_isomap(E_train_flatten, imgs_train, outFile)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YBJ9tB-VBTq5","colab_type":"text"},"source":["# Community Detection"]},{"cell_type":"code","metadata":{"id":"5WEv4QRABcQO","colab_type":"code","colab":{}},"source":["#calculate distance matric\n","dis_matric = sklearn.metrics.pairwise.pairwise_distances(E_train_flatten, metric='euclidean')\n","print(\"Saving distance matric...\")\n","outFile = os.path.join(outPath, \"dis_matric\")\n","np.save(outFile, dis_matric)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KxwHR-6_CpNa","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}